{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Motion Displacement RMS vs Time\n",
    "\n",
    "*an example simple tutorial for getting seismic data, computing the power spectral densities, extracting the RMS and plotting*\n",
    "\n",
    "Required:\n",
    "\n",
    "- python\n",
    "- obspy (and its dependencies)\n",
    "- pandas\n",
    "- jupyter\n",
    "- notebook\n",
    "- tqdm\n",
    "\n",
    "this should be easy to set up in a conda env: ``conda create -c conda-forge -n covid python=3.7 obspy pandas jupyter notebook tqdm``\n",
    "\n",
    "Author: Thomas Lecocq @seismotom, Fred Massin @fmassin, Claudio Satriano @claudiodsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:15:11.243647Z",
     "start_time": "2020-04-30T10:15:03.015965Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42 # to edit text in Illustrator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "from obspy import UTCDateTime, read, read_inventory\n",
    "from obspy.clients.filesystem.sds import Client\n",
    "\n",
    "from obspy.signal import PPSD\n",
    "\n",
    "import seismosocialdistancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seismosocialdistancing' from '/home/dariaorogom/Sismologia/seismosocialdistancing.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(seismosocialdistancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Start/End dates and Seismic Channel\n",
    "\n",
    "You'll have to make sure the seed_id you request is indeed available from the ``data_provider``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:15:11.263582Z",
     "start_time": "2020-04-30T10:15:11.250630Z"
    }
   },
   "outputs": [],
   "source": [
    "start = UTCDateTime(\"2022-12-01\")\n",
    "# Leaving UTCDateTime() empty means \"now\":\n",
    "end = UTCDateTime(\"2023-1-31\")\n",
    "\n",
    "network = \"AM\"\n",
    "station = \"R95F0\"\n",
    "location = \"00\"\n",
    "channel = \"HDF\"\n",
    "dataset = \"CGEO\"\n",
    "time_zone = 'America/Mexico_City'\n",
    "sitedesc = \"Querétaro (Querétaro, MX)\"\n",
    "\n",
    "data_provider = \"/home/dariaorogom/Desktop/Infra\"\n",
    "logo = None # 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Logo_SED_2014.png/220px-Logo_SED_2014.png'\n",
    "#bans = {\"2020-03-15 00:00\":'Restaurants/Bars/Schools closed', \n",
    "#        \"2020-03-18 12:00\":'Non-essential shops closed'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download the seismic waveform data\n",
    "\n",
    "This step is coded so that only the last day is redownloaded if the daily files are present on the disk.\n",
    "\n",
    "The request gets the target day +- 30 minutes to avoid having gaps at the end of each day (need 1 window covering midnight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:15:12.573241Z",
     "start_time": "2020-04-30T10:15:11.273560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching CGEO_2023-01-31_AM.R95F0.00.HDF.mseed: 100%|█| 62/62 [01:20<00:00,  1.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory created at 2023-07-04T22:11:40.245489Z\n",
      "\tSending institution: scxml import (ObsPy Inventory)\n",
      "\tContains:\n",
      "\t\tNetworks (1):\n",
      "\t\t\tAM\n",
      "\t\tStations (8):\n",
      "\t\t\tAM.R6417 (Casa-Juan)\n",
      "\t\t\tAM.R7E22 (Casa-Adolfo)\n",
      "\t\t\tAM.R8358 (Casa)\n",
      "\t\t\tAM.R95F0 (Casa-Alex)\n",
      "\t\t\tAM.RD07C (Montegrande-Colima)\n",
      "\t\t\tAM.RDBC3 (Oficina)\n",
      "\t\t\tAM.RE7AC (Casa Liliana)\n",
      "\t\t\tAM.REDAC (FACIMAR)\n",
      "\t\tChannels (8):\n",
      "\t\t\tAM.R6417.00.HDF, AM.R7E22.00.HDF, AM.R8358.00.HDF, AM.R95F0.00.HDF\n",
      "\t\t\tAM.RD07C.00.HDF, AM.RDBC3.00.HDF, AM.RE7AC.00.HDF, \n",
      "\t\t\tAM.REDAC.00.HDF\n"
     ]
    }
   ],
   "source": [
    "datelist = pd.date_range(start.datetime, min(end, UTCDateTime()).datetime, freq=\"D\")\n",
    "c = Client(data_provider)\n",
    "\n",
    "nslc = \"{}.{}.{}.{}\".format(network, station, location, channel)\n",
    "# make sure that wildcard characters are not in nslc\n",
    "nslc = nslc.replace(\"*\", \"\").replace(\"?\", \"\")\n",
    "pbar = tqdm.tqdm(datelist)\n",
    "for day in pbar:\n",
    "    datestr = day.strftime(\"%Y-%m-%d\")\n",
    "    fn = \"{}_{}_{}.mseed\".format(dataset, datestr, nslc)\n",
    "    if day != UTCDateTime().datetime and os.path.isfile(fn):\n",
    "        continue\n",
    "    else:\n",
    "        pbar.set_description(\"Fetching %s\" % fn)\n",
    "        st = c.get_waveforms(network, station, location, channel,\n",
    "                             UTCDateTime(day)-1801, UTCDateTime(day)+86400+1801, attach_response=True)\n",
    "        #st.write(fn)\n",
    "resp = read_inventory(\"Infra.xml\")\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resp.write(\"RD07C.xml\",format=\"STATIONXML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {'sensitivity':resp[0][0][0].response.instrument_sensitivity.value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensitivity': 4000.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute PPSDs using custom parameters\n",
    "\n",
    "These parameters are set to allow the PSDs to be \"nervous\", not as smooth as the default PQLX ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:15:17.692669Z",
     "start_time": "2020-04-30T10:15:12.580221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CGEO_2022-12-01_AM.R95F0.00.HDF.mseed:   0%|  | 0/62 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CGEO_2022-12-01_AM.R95F0.00.HDF.mseed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m fn_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset, datestr, nslc)\n\u001b[1;32m      6\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn_in)\n\u001b[0;32m----> 7\u001b[0m stall \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mseedid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([tr\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m stall])):\n\u001b[1;32m      9\u001b[0m     fn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset, datestr, mseedid)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/obspy/core/util/decorator.py:297\u001b[0m, in \u001b[0;36mmap_example_filename.<locals>._map_example_filename\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m                     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/obspy/core/stream.py:208\u001b[0m, in \u001b[0;36mread\u001b[0;34m(pathname_or_url, format, headonly, starttime, endtime, nearest_sample, dtype, apply_calib, check_compression, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     st \u001b[38;5;241m=\u001b[39m _create_example_stream(headonly\u001b[38;5;241m=\u001b[39mheadonly)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43m_generic_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathname_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(st) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# try to give more specific information why the stream is empty\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_magic(pathname_or_url) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m glob(pathname_or_url):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/obspy/core/util/base.py:656\u001b[0m, in \u001b[0;36m_generic_reader\u001b[0;34m(pathname_or_url, callback_func, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file matching file pattern: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m pathname)\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mhas_magic(pathname) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(pathname)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m--> 656\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m, pathname)\n\u001b[1;32m    658\u001b[0m generic \u001b[38;5;241m=\u001b[39m callback_func(pathnames[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pathnames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CGEO_2022-12-01_AM.R95F0.00.HDF.mseed'"
     ]
    }
   ],
   "source": [
    "force_reprocess = False\n",
    "pbar = tqdm.tqdm(datelist)\n",
    "for day in pbar:\n",
    "    datestr = day.strftime(\"%Y-%m-%d\")\n",
    "    fn_in = \"{}_{}_{}.mseed\".format(dataset, datestr, nslc)\n",
    "    pbar.set_description(\"Processing %s\" % fn_in)\n",
    "    stall = read(fn_in, headonly=True)\n",
    "    for mseedid in list(set([tr.id for tr in stall])):\n",
    "        fn_out = \"{}_{}_{}.npz\".format(dataset, datestr, mseedid)\n",
    "        if os.path.isfile(fn_out) and not force_reprocess:\n",
    "            continue\n",
    "        st = read(fn_in, sourcename=mseedid)\n",
    "        st.attach_response(resp)\n",
    "        ppsd = PPSD(st[0].stats, metadata=resp,\n",
    "                    ppsd_length=1800, overlap=0.5,\n",
    "                    period_smoothing_width_octaves=0.025,\n",
    "                    period_step_octaves=0.0125,\n",
    "                    period_limits=(0.02, 1),\n",
    "                    db_bins=(-200, 20, 0.25),\n",
    "                    special_handling='infrasound')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            ppsd.add(st)\n",
    "        ppsd.save_npz(fn_out[:-4])\n",
    "        del st, ppsd\n",
    "    del stall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Reload daily PSDs from the disk and create a single PPSD object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:15:19.847047Z",
     "start_time": "2020-04-30T10:15:17.699630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppsds = {}\n",
    "pbar = tqdm.tqdm(datelist)\n",
    "for day in pbar:\n",
    "    datestr = day.strftime(\"%Y-%m-%d\")\n",
    "    fn_pattern = \"{}_{}_*.npz\".format(dataset, datestr)\n",
    "    pbar.set_description(\"Reading %s\" % fn_pattern)\n",
    "    for fn in glob(fn_pattern):\n",
    "        mseedid = fn.replace(\".npz\", \"\").split(\"_\")[-1]\n",
    "        if mseedid not in ppsds:\n",
    "            ppsds[mseedid] = PPSD.load_npz(fn)#, allow_pickle=True)\n",
    "        else:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                ppsds[mseedid].add_npz(fn)#, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Standard plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:16:11.370125Z",
     "start_time": "2020-04-30T10:15:19.853030Z"
    }
   },
   "outputs": [],
   "source": [
    "#[ppsd.plot(max_percentage=10,show_noise_models=True) for mseedid, ppsd in ppsds.items()]\n",
    "[ppsd.plot_temporal([0.2,0.1,1/20,1/30]) for mseedid, ppsd in ppsds.items()]\n",
    "#[ppsd.plot_spectrogram(clim=(-100,0)) for mseedid, ppsd in ppsds.items()]\n",
    "plt.ylim(0,-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ppsd.plot(max_percentage=10,show_noise_models=True,period_lim=(0.02, 1),show_mean=True) for mseedid, ppsd in ppsds.items()]\n",
    "#[ppsd.plot(max_percentage=10,show_noise_models=False,xaxis_frequency=True) for mseedid, ppsd in ppsds.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Process PSDs to extract the RMS(displacement)\n",
    "\n",
    "This can be done for multiple filters at once (``freqs`` below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:16:11.500206Z",
     "start_time": "2020-04-30T10:16:11.375112Z"
    }
   },
   "outputs": [],
   "source": [
    "def dfrms(a):\n",
    "    return np.sqrt(np.trapz(a.values, a.index))\n",
    "\n",
    "def df_rms(d, freqs, output=\"VEL\"):\n",
    "    d = d.dropna(axis=1, how='all')\n",
    "    RMS = {}\n",
    "    for fmin, fmax in freqs:\n",
    "        \n",
    "        ix = np.where((d.columns>=fmin) & (d.columns<=fmax))[0]\n",
    "        spec = d.iloc[:,ix]\n",
    "        f = d.columns[ix]\n",
    "        \n",
    "        w2f = (2.0 * np.pi * f)\n",
    "\n",
    "        # The acceleration power spectrum (dB to Power! = divide by 10 and not 20!)\n",
    "        amp = 10.0**(spec/10.) \n",
    "        if output == \"ACC\":\n",
    "            RMS[\"%.1f-%.1f\"%(fmin, fmax)] = amp.apply(dfrms, axis=1)\n",
    "            continue\n",
    "        \n",
    "        # velocity power spectrum (divide by omega**2)\n",
    "        vamp = amp / w2f**2\n",
    "        if output == \"VEL\":\n",
    "            RMS[\"%.1f-%.1f\"%(fmin, fmax)] = vamp.apply(dfrms, axis=1)\n",
    "            continue\n",
    "                \n",
    "        # displacement power spectrum (divide by omega**2)\n",
    "        damp = vamp / w2f**2\n",
    "       \n",
    "        RMS[\"%.1f-%.1f\"%(fmin, fmax)] = damp.apply(dfrms, axis=1)\n",
    "\n",
    "    return pd.DataFrame(RMS, index=d.index)#.tz_localize(\"UTC\")#.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:16:20.846235Z",
     "start_time": "2020-04-30T10:16:11.508185Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define frequency bands of interest:\n",
    "freqs = [(0.1,1.0),(1.0,20.0),(4.0,14.0),(20.0,40.0)]\n",
    "\n",
    "displacement_RMS = {}\n",
    "for mseedid, ppsd in tqdm.tqdm(ppsds.items()):\n",
    "    ind_times = pd.DatetimeIndex([d.datetime for d in ppsd.current_times_used])\n",
    "    data = pd.DataFrame(ppsd.psd_values, index=ind_times, columns=1./ppsd.period_bin_centers)\n",
    "    data = data.sort_index(axis=1)\n",
    "    displacement_RMS[mseedid] = df_rms(data, freqs, output=\"ACC\")\n",
    "    displacement_RMS[mseedid].to_csv(\"%s.csv\" % mseedid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(seismosocialdistancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Custom plot for a single frequency band:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekday / Time of day Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise distribution over time of the day  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = displacement_RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channelcode in list(set([k[:-1] for k in displacement_RMS])):\n",
    "    print(channelcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band=\"20.0-40.0\"\n",
    "for o in 'ZENF':\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[channelcode[-2:]+o] = displacement_RMS[channelcode+o][band]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main=channelcode[-2:]+o\n",
    "main\n",
    "data[main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize_tz_and_reindex(df, freq=\"15Min\", time_zone = \"Europe/Brussels\"):\n",
    "    return df.copy().tz_localize(\"UTC\").dropna().tz_convert(time_zone).tz_localize(None).resample(freq).mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[main] = localize_tz_and_reindex(data[main], \"30Min\", time_zone = time_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday']\n",
    "# Just a bunch of helper functions\n",
    "def stack_wday_time(df):\n",
    "    \"\"\"Takes a DateTimeIndex'ed DataFrame and returns the unstaked table: hours vs day name\"\"\"\n",
    "    return df.groupby(level=(0,1)).median().unstack(level=-1).T.droplevel(0)[days]#*1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postloc = data[main].loc[list(bans.keys())[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postloc = postloc.set_index([postloc.index.day_name(), postloc.index.hour+postloc.index.minute/60.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_wday_time(postloc).plot(figsize=(14,8),cmap = cmap)\n",
    "                \n",
    "plt.title(\"Daily Noise Levels in %s\" % (channelcode[:]+main[-1]))\n",
    "plt.ylabel(\"Pa\")\n",
    "plt.xlabel(\"Hour of day (local time)\")\n",
    "plt.grid()\n",
    "plt.xlim(0,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_hours(N):\n",
    "    hours = np.deg2rad(np.linspace(0, 360, N-1, endpoint=False))\n",
    "    hours = np.append(hours, hours[0])\n",
    "    return hours\n",
    "def clock24_plot_commons(ax):\n",
    "    # Set the circumference labels\n",
    "    ax.set_xticks(np.linspace(0, 2*np.pi, 24, endpoint=False))\n",
    "    ax.set_xticklabels([\"%i h\"%i for i in range(24)], fontsize=8)\n",
    "    #ax.set_yticklabels([\"%i nm\" % i for i in np.arange(0,100, 10)], fontsize=7)\n",
    "    ax.yaxis.set_tick_params(labelsize=10)\n",
    "\n",
    "    # Make the labels go clockwise\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.legend(loc='center left',bbox_to_anchor=(1, 0, 0.5, 1.8))\n",
    "    #ax.legend(loc=\"center right')\n",
    "    # Place 0 at the top\n",
    "    ax.set_theta_offset(np.pi/2.0)\n",
    "    plt.xlabel(\"Hour (local time)\", fontsize=10)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ax = plt.subplot(polar=True)\n",
    "_ = stack_wday_time(postloc).copy()\n",
    "_.loc[len(_)+1] = _.iloc[0]\n",
    "_.index = radial_hours(len(_))\n",
    "_.plot(ax=ax)\n",
    "#plt.title(\"Infrasound\", fontsize=12)\n",
    "clock24_plot_commons(ax)\n",
    "plt.suptitle(\"Day/Hour Median Noise levels %s\\nStation %s - [%s] Hz\" % (sitedesc,channelcode[:]+main[-1],band), fontsize=12)\n",
    "plt.savefig('R8358_Clock.png')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
